{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RMDL_BERT.ipynb",
      "provenance": [],
      "mount_file_id": "1dYYIIFUFDy2rXSX8rzLvmAu6JAgPV967",
      "authorship_tag": "ABX9TyP6mXhB5KJ/V3Lt6Dc5p3CZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/remanx2558/MIDBReviews/blob/master/RMDL_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMub81zqkQxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "b267a010-f1d4-42b9-d6c4-ae8d535a95ff"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/df/ab6d927d6162657f30eb0ae3c534c723c28c191a9caf6ee68ec935df3d0b/bert-for-tf2-0.14.5.tar.gz (40kB)\n",
            "\r\u001b[K     |████████                        | 10kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 30kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 3.9MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.5-cp36-none-any.whl size=30317 sha256=f07782c819ba8b2b97fb1e5fddd8ffc151be5cb9895a727aabf69815c322bf6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/70/a2/be357037dd2cbdcaeb0add1fdf083be6a600ca65ee1f68751c\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7304 sha256=29128003e092485914b11dbf3158c10a869523fc22f265367b61e1602bfed84b\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19475 sha256=28d1b5e63662b5c4c267342159968aba6f252fa5b1c37edbea54e42273588508\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.5 params-flow-0.8.2 py-params-0.9.7\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 8.2MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7Tc8S57IzJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6vPDQn9IzON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLyQ0BA6IzXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmiGWlgPIzUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKCVyYg8IzSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDpWHI1xkRT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Htj47jHkRXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import itertools\n",
        "import gensim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import zeros\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clm_nvCJkRav",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0ff7d7e3-7227-4411-c64e-e29b1eb73ebb"
      },
      "source": [
        "# Importing dataset\n",
        "reviews_df = pd.read_csv(r\"/content/drive/My Drive/malia/train.csv\")\n",
        "reviews_df.isnull().values.any()\n",
        "reviews_df.sentiment= reviews_df.sentiment.fillna(0.0).astype(int)#this will conver float into int and also manage missing values\n",
        "print(reviews_df.dtypes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text         object\n",
            "sentiment     int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-YKGOnnkRdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(text):\n",
        "    '''\n",
        "    '''\n",
        "    text = text.lower()\n",
        "    text = text.replace(\"ain't\", \"am not\")\n",
        "    text = text.replace(\"aren't\", \"are not\")\n",
        "    text = text.replace(\"can't\", \"cannot\")\n",
        "    text = text.replace(\"can't've\", \"cannot have\")\n",
        "    text = text.replace(\"'cause\", \"because\")\n",
        "    text = text.replace(\"could've\", \"could have\")\n",
        "    text = text.replace(\"couldn't\", \"could not\")\n",
        "    text = text.replace(\"couldn't've\", \"could not have\")\n",
        "    text = text.replace(\"should've\", \"should have\")\n",
        "    text = text.replace(\"should't\", \"should not\")\n",
        "    text = text.replace(\"should't've\", \"should not have\")\n",
        "    text = text.replace(\"would've\", \"would have\")\n",
        "    text = text.replace(\"would't\", \"would not\")\n",
        "    text = text.replace(\"would't've\", \"would not have\")\n",
        "    text = text.replace(\"didn't\", \"did not\")\n",
        "    text = text.replace(\"doesn't\", \"does not\")\n",
        "    text = text.replace(\"don't\", \"do not\")\n",
        "    text = text.replace(\"hadn't\", \"had not\")\n",
        "    text = text.replace(\"hadn't've\", \"had not have\")\n",
        "    text = text.replace(\"hasn't\", \"has not\")\n",
        "    text = text.replace(\"haven't\", \"have not\")\n",
        "    text = text.replace(\"haven't\", \"have not\")\n",
        "    text = text.replace(\"haven't\", \"have not\")\n",
        "    text = text.replace(\"haven't\", \"have not\")\n",
        "    text = text.replace(\"he'd\", \"he would\")\n",
        "    text = text.replace(\"haven't\", \"have not\")\n",
        "    text = text.replace(\"he'd've\", \"he would have\")\n",
        "    text = text.replace(\"'s\", \"\")\n",
        "    text = text.replace(\"'t\", \"\")\n",
        "    text = text.replace(\"'ve\", \"\")\n",
        "    text = text.replace(\".\", \" . \")\n",
        "    text = text.replace(\"!\", \" ! \")\n",
        "    text = text.replace(\"?\", \" ? \")\n",
        "    text = text.replace(\";\", \" ; \")\n",
        "    text = text.replace(\":\", \" : \")\n",
        "    text = text.replace(\",\", \" , \")\n",
        "    text = text.replace(\"´\", \"\")\n",
        "    text = text.replace(\"‘\", \"\")\n",
        "    text = text.replace(\"’\", \"\")\n",
        "    text = text.replace(\"“\", \"\")\n",
        "    text = text.replace(\"”\", \"\")\n",
        "    text = text.replace(\"\\'\", \"\")\n",
        "    text = text.replace(\"\\\"\", \"\")\n",
        "    text = text.replace(\"-\", \"\")\n",
        "    text = text.replace(\"–\", \"\")\n",
        "    text = text.replace(\"—\", \"\")\n",
        "    text = text.replace(\"[\", \"\")\n",
        "    text = text.replace(\"]\",\"\")\n",
        "    text = text.replace(\"{\",\"\")\n",
        "    text = text.replace(\"}\", \"\")\n",
        "    text = text.replace(\"/\", \"\")\n",
        "    text = text.replace(\"|\", \"\")\n",
        "    text = text.replace(\"(\", \"\")\n",
        "    text = text.replace(\")\", \"\")\n",
        "    text = text.replace(\"$\", \"\")\n",
        "    text = text.replace(\"+\", \"\")\n",
        "    text = text.replace(\"*\", \"\")\n",
        "    text = text.replace(\"%\", \"\")\n",
        "    text = text.replace(\"#\", \"\")\n",
        "    text = text.replace(\"\\n\", \" \\n \")\n",
        "    text = text.replace(\"\\n\", \"\")\n",
        "    text = text.replace(\"_\", \" _ \")\n",
        "    text = text.replace(\"_\", \"\")\n",
        "    text = ''.join([i for i in text if not i.isdigit()])\n",
        "\n",
        "    return text\n",
        "\n",
        "texts = reviews_df['text'].values\n",
        "\n",
        "cleaned_texts = [clean(r) for r in texts] \n",
        "\n",
        "reviews_df['text'] = cleaned_texts\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCaca410kRgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffling data\n",
        "reviews_df = reviews_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Extracting all text\n",
        "texts = reviews_df['text'].values\n",
        "reviews_text = []\n",
        "\n",
        "for p in zip(texts) : \n",
        " reviews_text.append(p)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yukeWDY-kRjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing training data\n",
        "\n",
        "\n",
        "# Creating datasets\n",
        "dict1 ={\n",
        "    'reviews' : reviews_df['text'],\n",
        "    'labels' : reviews_df['sentiment']\n",
        "}\n",
        "sentiment_df = pd.DataFrame.from_dict(dict1)\n",
        "\n",
        "\n",
        "dict2 ={\n",
        "    'reviews_text' : reviews_df['text']\n",
        "}\n",
        "reviews_text_df = pd.DataFrame.from_dict(dict2)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYgedzVwkRm2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "6b8b2212-702a-4f90-899c-08b5b99589e8"
      },
      "source": [
        "\n",
        "print(sentiment_df[:10])\n",
        "print(reviews_text_df[:10])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             reviews  labels\n",
            "0  i still have grainy  ,   late night  ,   nocab...       0\n",
            "1  this film could have been a silent movie  ;   ...       0\n",
            "2  this wasn the major disaster that i was expect...       1\n",
            "3  it was extremely low budgetit some scenes it l...       0\n",
            "4  based on a true story of how a man ahead of hi...       0\n",
            "5  dolph lundgren is back  !   detention marks do...       0\n",
            "6  could not believe it  !   clipped sentences  ?...       1\n",
            "7  scary movie  isn as funny as its predecessors ...       1\n",
            "8  stupid and just plain weird movie about some k...       1\n",
            "9  i loved this movie  ,   and i am one of the ol...       0\n",
            "                                        reviews_text\n",
            "0  i still have grainy  ,   late night  ,   nocab...\n",
            "1  this film could have been a silent movie  ;   ...\n",
            "2  this wasn the major disaster that i was expect...\n",
            "3  it was extremely low budgetit some scenes it l...\n",
            "4  based on a true story of how a man ahead of hi...\n",
            "5  dolph lundgren is back  !   detention marks do...\n",
            "6  could not believe it  !   clipped sentences  ?...\n",
            "7  scary movie  isn as funny as its predecessors ...\n",
            "8  stupid and just plain weird movie about some k...\n",
            "9  i loved this movie  ,   and i am one of the ol...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-kaLZ7skRrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    # Removing html tags\n",
        "    sentence = remove_tags(sen)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZlwLUlYkRuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_AIeHO8neUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = []\n",
        "sentences = list(sentiment_df['reviews'])\n",
        "for sen in sentences:\n",
        "    reviews.append(preprocess_text(sen))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RyajSfwneYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5024a59-f92d-4c5a-e04b-6e4b1b943477"
      },
      "source": [
        "print(sentiment_df.columns.values)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['reviews' 'labels']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-ULIAPHnecN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc340e1d-d451-4b02-ef20-4b209008c170"
      },
      "source": [
        "sentiment_df.labels.unique()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szTdJqH9nefm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "433c6d76-5a9d-45f8-cde9-4afbe1c90b71"
      },
      "source": [
        "print(reviews[20])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "robert culp they call his character doctor think he vet or something and family move to an affluent lowtax zerolawenforcement suburb lanternjawed culp and his dog are nearly killed when some local idiot neighbor kids get drunk and go cruising through his front yard at mph he presses charges which arouses the kids ire and suddenly him and his family are the victims of violent and disturbing prank campaign marilyn manson er marlyn mason rather plays his fretful boiledcelery wife who urges him not to use violence against his sneering nemeses and who really just wants to move somewhere with decent public services but the system is getting culp nowhere and he not about to leave his house because of some punk kids and their crazy rock and roll music and we all know what movie people do when the system fails but this is based on true story which makes it even better it should be noted that while the villainous hooligans do have convenient funkomatic teenage theme music that warns us when theyre up to no good this film actually ends up treating the age brackets evenhandedly really it does not make big generational thing out of it kudos for that anyway if you like dogs or at least believe in protecting their civil rights like me and you like justice and you like fire and you like justice for dogs by way of fire and you think people who skitter nervously out of troubled communities are too damn soft then this flick ethos is up your alley no it not really good at least not in any widely recognized sense of the word there nothing subtle or understated or clever about it it just sort of featurelength psa for vigilantism it does however capture the feeling of some memorable scenes in other beloved works remember in frank miller the dark knight returns when batman leads the mutants on horseback to reclaim gotham city remember that scene in christmas story where the kid pounds the bully face in remember how cool that was or do you just really hate being looked at funny by your neighbors yeah mon unfortunately this was madefortv movie that just happened to catch at am on my local wb affiliate and it probably not destined for dvd release but after being inspired by this film do you think im gonna just sit here and take it \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUrfQPOLneit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = sentiment_df['labels']\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg-wK_lnnell",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRl34exyneod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(reviews[10]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_THK7w-neut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_reviews(reviews):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(reviews))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbKCD7w7neyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_reviews = [tokenize_reviews(review) for review in reviews]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acse-Q3Nne09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9d975c9d-893f-4ac0-87e7-0b3c845ced64"
      },
      "source": [
        "print(tokenized_reviews[10])\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1045, 2001, 2061, 9364, 1999, 2023, 3185, 2079, 2025, 2113, 2172, 2055, 1996, 2995, 2466, 2061, 2001, 9461, 2000, 2156, 2009, 2377, 2041, 2006, 2143, 1998, 16957, 2870, 2055, 2210, 14704, 1997, 2381, 2007, 2107, 3928, 2995, 2466, 1998, 2307, 5889, 2009, 2790, 2066, 2469, 10273, 5257, 2092, 4873, 1996, 9000, 3478, 2068, 2009, 2001, 2061, 7932, 2003, 2023, 3185, 2055, 2010, 5593, 2010, 2293, 2166, 2010, 2219, 11980, 2010, 4092, 3754, 2010, 6896, 2005, 1996, 9776, 10047, 2469, 2045, 2003, 2126, 2000, 13265, 2035, 1997, 2216, 2477, 2046, 2204, 2466, 2021, 2023, 3185, 2347, 2009, 2001, 2187, 3147, 3666, 3494, 2008, 2020, 4895, 25421, 3468, 2025, 2138, 1997, 2037, 13597, 2021, 2138, 1997, 2037, 12857, 2060, 2235, 6218, 2229, 1996, 3082, 11774, 2098, 6050, 2009, 1996, 26232, 2057, 2131, 2009, 2525, 2065, 2002, 2107, 13352, 2140, 2270, 5882, 2339, 4694, 2057, 5845, 2000, 2062, 2084, 1055, 3490, 29519, 2182, 1998, 2045, 1998, 2130, 2059, 3262, 1999, 18318, 13923]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQG0EEDIne4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_with_len = [[review, y[i]]\n",
        "                 for i, review in enumerate(tokenized_reviews)]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krHK_vi9ne7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.shuffle(reviews_with_len)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nYK5R0pkRxd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8e09f018-009f-4ceb-ad1c-3ab0dcc0f6be"
      },
      "source": [
        "print(reviews_with_len[:2])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1996, 2518, 2008, 2428, 4152, 2033, 2055, 2023, 3185, 2008, 2003, 1996, 2518, 2055, 2023, 3185, 2008, 3084, 2033, 8186, 5665, 2003, 2008, 2619, 2941, 3825, 2000, 2031, 2009, 2081, 2045, 2003, 7078, 2053, 3800, 2005, 1996, 4598, 1997, 2023, 3185, 2009, 2003, 2025, 17115, 2009, 2003, 2025, 2245, 4013, 22776, 2009, 2003, 2025, 14036, 2009, 2003, 2025, 2204, 2009, 2003, 5777, 17357, 2081, 1997, 22330, 7088, 3207, 1996, 4966, 2553, 22963, 2009, 2000, 10503, 6965, 4763, 2757, 1998, 2261, 2060, 11519, 5691, 2437, 1996, 12127, 15561, 16124, 2135, 5793, 2009, 2003, 2498, 2066, 2151, 2060, 3185, 2412, 2081, 2009, 2003, 2521, 2521, 4788, 1996, 4447, 1997, 2019, 5186, 16880, 4566, 2017, 2097, 2196, 5293, 2024, 1996, 5662, 1997, 2028, 10228, 1997, 27136, 2075, 3586, 7510, 2015, 3531, 2079, 2025, 2412, 5949, 2115, 2051, 3666, 2023, 3538, 1997, 11669, 2138, 2009, 2089, 2191, 2017, 25403, 1996, 2158, 2040, 2626, 2023, 3185, 2323, 2022, 8342, 2125, 1996, 3213, 9054, 5779, 2862, 1998, 2196, 3039, 2000, 2143, 2505, 2153, 2138, 2065, 2002, 2245, 2023, 2001, 3185, 4276, 2437, 2002, 2763, 2515, 2025, 2031, 2172, 1997, 2505, 2000, 3749, 1999, 1996, 2925, 5717, 3340, 2089, 24665, 7716, 2031, 8673, 2006, 1996, 3969, 1997, 3087, 15140, 2438, 2000, 2156, 2023, 2572, 2183, 2000, 2175, 23251, 2085], 1], [[2364, 4323, 1999, 2023, 6530, 4302, 2003, 2008, 7195, 2003, 9841, 2190, 2366, 3147, 12834, 18343, 2003, 2004, 3147, 1999, 2023, 2143, 2004, 2016, 2003, 3376, 18343, 2003, 2019, 5373, 2021, 2007, 9252, 8779, 1999, 2014, 8722, 13179, 2005, 1996, 2919, 4364, 2016, 18881, 2035, 1996, 2126, 2039, 1996, 4094, 2000, 2383, 2042, 6080, 2527, 5669, 2247, 2007, 2014, 3920, 2905, 2070, 2086, 3283, 18343, 2004, 7673, 7084, 2038, 2699, 2000, 3796, 2041, 1996, 2886, 2013, 2014, 2166, 2004, 2190, 2016, 2064, 2014, 2905, 27793, 2003, 2471, 16571, 22282, 2004, 2765, 1997, 1996, 12603, 2061, 1996, 3638, 2003, 2196, 2521, 2013, 2014, 2568, 2028, 2154, 7673, 5927, 2028, 1997, 2014, 17857, 2006, 1996, 2395, 1999, 1042, 2016, 23311, 8779, 4076, 2032, 2000, 3347, 11082, 2032, 4060, 2014, 2039, 2059, 2043, 2027, 2890, 2894, 1999, 2010, 20425, 2927, 2000, 2191, 2293, 2016, 11758, 2032, 2320, 1999, 1996, 8991, 18400, 2015, 2320, 1999, 1996, 4167, 2023, 1999, 1996, 3098, 3496, 8038, 10657, 2293, 2023, 7455, 4801, 3203, 2016, 2288, 2014, 18402, 3442, 4606, 7673, 2003, 2658, 3063, 5128, 2035, 2014, 4963, 2006, 10683, 2127, 2085, 2044, 23448, 2014, 2034, 2566, 2361, 7673, 16484, 12197, 20010, 16021, 2361, 4302, 25668, 2832, 1996, 4840, 4126, 3496, 2044, 1996, 2303, 2003, 2179, 1999, 1996, 28353, 5149, 2059, 2016, 23862, 2070, 17109, 9454, 14189, 2040, 2024, 2038, 28886, 2308, 2006, 1996, 2395, 7879, 2014, 2905, 1999, 8329, 2188, 2059, 3632, 6289, 16671, 2075, 1999, 2624, 14174, 6187, 2039, 1996, 3023, 2073, 1996, 9040, 2724, 2165, 2173, 2086, 3283, 2007, 2062, 10432, 1999, 2014, 15940, 1998, 2062, 10663, 1999, 2014, 2568, 2256, 18869, 2128, 3669, 6961, 1996, 9040, 2503, 2014, 2132, 2007, 14954, 9131, 2004, 2016, 3310, 3553, 2000, 23448, 2169, 4745, 9680, 2923, 2025, 13191, 2000, 2149, 2157, 16072, 2015, 2043, 2009, 3310, 2000, 23280, 2030, 23448, 6355, 4735, 2079, 2025, 2022, 14038, 3993, 2005, 2010, 2219, 23277, 29574, 8438, 2057, 3342, 1996, 4126, 1998, 1996, 6114, 2002, 17303, 2107, 7383, 2824, 3886, 2015, 7673, 2000, 4139, 1996, 9495, 2006, 2169, 1997, 2014, 17857, 2320, 1999, 1996, 8991, 18400, 2015, 2320, 1999, 1996, 4167, 2802, 1996, 3185, 5019, 1997, 7673, 7195, 2024, 25338, 2007, 2204, 6335, 6530, 4302, 11221, 2185, 2070, 18542, 10230, 1999, 4157, 4497, 3342, 2175, 3805, 2191, 2026, 2154, 2101, 2006, 2002, 17016, 2000, 3357, 2006, 7196, 4845, 2040, 2094, 2074, 23637, 25668, 1999, 10816, 7764, 2066, 2002, 2052, 3357, 2006, 3899, 2358, 2975, 2402, 2931, 22410, 7904, 4582, 2044, 16235, 2004, 2065, 2000, 2360, 2215, 2000, 2031, 2115, 3336, 2026, 5440, 3496, 2003, 2069, 2055, 2781, 2046, 1996, 2895, 2043, 4302, 17016, 1998, 25966, 6132, 25303, 13897, 5795, 2315, 16215, 16570, 14270, 2046, 10611, 21887, 2854, 2076, 2010, 12787, 5030, 7684, 2012, 1996, 2928, 10239, 3309, 2745, 26918, 6844, 6090, 26067, 20806, 1999, 23834, 2462, 2515, 6919, 3105, 2004, 1996, 8254, 3993, 13897, 2123, 2130, 2065, 2002, 2069, 1999, 2028, 3496, 5996, 1999, 2087, 8663, 6371, 6129, 5450, 2174, 4302, 13460, 2024, 2025, 2058, 2007, 2664, 1996, 7764, 7196, 6080, 1998, 16215, 16570, 14270, 21863, 2818, 3549, 2169, 3535, 2000, 25683, 4302, 1999, 2048, 2485, 8551, 6850, 5019, 1998, 2087, 1997, 2068, 2919, 4364, 2203, 2039, 5996, 27762, 9805, 2361, 2070, 1997, 1996, 3282, 13068, 3310, 2125, 2004, 4895, 7076, 21649, 3898, 4808, 2559, 2066, 16235, 1996, 2472, 2089, 2031, 2042, 5458, 2008, 2154, 1997, 5008, 2023, 3185, 2021, 2045, 2069, 2061, 2116, 3971, 2017, 2064, 18365, 2158, 2007, 10432, 1996, 7196, 4268, 3280, 2172, 2062, 5541, 2135, 2295, 2004, 2027, 2119, 6402, 2000, 2331, 1998, 19549, 1999, 1042, 3016, 4010, 2015, 2026, 2540, 2007, 2061, 2172, 6355, 7848, 2856, 2012, 16021, 2361, 25668, 2010, 23029, 4604, 2032, 2000, 2624, 14174, 2000, 3046, 2000, 2131, 2070, 4281, 2006, 1996, 15977, 18781, 6593, 16940, 4288, 2004, 7673, 7084, 4126, 2003, 2085, 2124, 2021, 2025, 2077, 4302, 18058, 2028, 1997, 2010, 3297, 20855, 3406, 10760, 20209, 4063, 4974, 2098, 29521, 21673, 2015, 2293, 2008, 4302, 2096, 2256, 5394, 2039, 15703, 1996, 2334, 10558, 1998, 4480, 1999, 2624, 14174, 2048, 2062, 9916, 4148, 2168, 1051, 2006, 22889, 5243, 9096, 13971, 19949, 1998, 2006, 2019, 8053, 16748, 13699, 2100, 8051, 10670, 2059, 4302, 6010, 7673, 2027, 2424, 2027, 2119, 5993, 2006, 5739, 2107, 2004, 2375, 1998, 2344, 2437, 1996, 5905, 3477, 4385, 2071, 2980, 2293, 3496, 2022, 1999, 1996, 2125, 2075, 2574, 2020, 2419, 2000, 2903, 2074, 2008, 3494, 11113, 28819, 1999, 2023, 8391, 2319, 6010, 2613, 10169, 4126, 3689, 1998, 2057, 2131, 2000, 3113, 8782, 2100, 7087, 5149, 3489, 2315, 4097, 2063, 2380, 7076, 2040, 2119, 29348, 1998, 14036, 4097, 2063, 2275, 2039, 7673, 9040, 2005, 2014, 6898, 2086, 2077, 1998, 5806, 2131, 5106, 2776, 1996, 2624, 14174, 2610, 2708, 2209, 2011, 10539, 24201, 6849, 2099, 6986, 7632, 3070, 2571, 1996, 5689, 3648, 1999, 6865, 7861, 2152, 2003, 13939, 2012, 10238, 2007, 25668, 6317, 2147, 3141, 2000, 1996, 10250, 18781, 6593, 20936, 2229, 2127, 2057, 2424, 2041, 2008, 2010, 2219, 20274, 2365, 2001, 2028, 1997, 1996, 6080, 1997, 9680, 5130, 2172, 2066, 7673, 2905, 2708, 5553, 5582, 2365, 2003, 2085, 16571, 22282, 4639, 2021, 5533, 5506, 2011, 8056, 2009, 3685, 2203, 2182, 2295, 1996, 22212, 9680, 2923, 6898, 10872, 2085, 12631, 4801, 3366, 2595, 12181, 1997, 4735, 9297, 1999, 2013, 7136, 2022, 10841, 2480, 4097, 2063, 3333, 27211, 2006, 7673, 18654, 2075, 2032, 2039, 2000, 2624, 14174, 2000, 4652, 2062, 22679, 10872, 25126, 2012, 4097, 2063, 2160, 2021, 2010, 10984, 2003, 2035, 3308, 1998, 2002, 4727, 2077, 2002, 2064, 5247, 2062, 2051, 2007, 4097, 2063, 3262, 2349, 2000, 1996, 2755, 2008, 2016, 2144, 2042, 2741, 2000, 1996, 2479, 1997, 1996, 10721, 4649, 5092, 2229, 2011, 2915, 2013, 7673, 17863, 18224, 10872, 3084, 15358, 2012, 2146, 2197, 2007, 7673, 22079, 2075, 2005, 2032, 7143, 5252, 4372, 6342, 2229, 2004, 4302, 5363, 2000, 2562, 2122, 2048, 2013, 4288, 2169, 2060, 2009, 2035, 4332, 2041, 2092, 1999, 1996, 2203, 2007, 1996, 2204, 14891, 1998, 1996, 2204, 3124, 3788, 2125, 2046, 1996, 10434, 2362, 2000, 3376, 23455, 13109, 8684, 5132, 2299], 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-MkrIgmoTKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "33f75dad-be6e-4df8-da22-ba36f5c58aa6"
      },
      "source": [
        "reviews_with_len.sort(key=lambda x: x[2])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-3be825373ff8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreviews_with_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-3be825373ff8>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreviews_with_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEnkxeWcI1LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_reviews_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X717zodPI1Oa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_reviews_labels, output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbxxbJZ8I1RS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP9S804MI1fj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "29b07604-8f28-41e1-af3d-0e3c8cbf51b8"
      },
      "source": [
        "\n",
        "\n",
        "next(iter(batched_dataset))\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 1015), dtype=int32, numpy=\n",
              " array([[ 1996,  2518,  2008, ...,     0,     0,     0],\n",
              "        [ 2364,  4323,  1999, ...,     0,     0,     0],\n",
              "        [ 2009,  3504,  2066, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [ 2250, 12155, 10270, ...,     0,     0,     0],\n",
              "        [ 1999,  3290,  2103, ...,     0,     0,     0],\n",
              "        [ 2750,  2108,  3185, ...,     0,     0,     0]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "        0, 0, 1, 1, 1, 1, 0, 0, 0, 1], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSw-CESZI1nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import math\n",
        "TOTAL_BATCHES = math.ceil(len(sorted_reviews_labels) / BATCH_SIZE)\n",
        "TEST_BATCHES = TOTAL_BATCHES // 10\n",
        "batched_dataset.shuffle(TOTAL_BATCHES)\n",
        "test_data = batched_dataset.take(TEST_BATCHES)\n",
        "train_data = batched_dataset.skip(TEST_BATCHES)\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMXPmyo7I1lY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIX7v_rLI1iV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TEXT_MODEL(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 embedding_dimensions=128,\n",
        "                 cnn_filters=50,\n",
        "                 dnn_units=512,\n",
        "                 model_output_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"text_model\"):\n",
        "        super(TEXT_MODEL, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocabulary_size,\n",
        "                                          embedding_dimensions)\n",
        "        #self.rnn_layer = layers.Bidirectional(self.rnn_layer.layers.LSTM(32)),\n",
        "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=2,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=3,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=4,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if model_output_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=model_output_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        l = self.embedding(inputs)\n",
        "        l_1 = self.cnn_layer1(l) \n",
        "        l_1 = self.pool(l_1) \n",
        "        l_2 = self.cnn_layer2(l) \n",
        "        l_2 = self.pool(l_2)\n",
        "        l_3 = self.cnn_layer3(l)\n",
        "        l_3 = self.pool(l_3) \n",
        "        concatenated = tf.concat([l_1, l_2, l_3,], axis=-1) # (batch_size, 4 * rmdl_filters)\n",
        "        concatenated = self.dense_1(concatenated)\n",
        "        concatenated = self.dropout(concatenated, training)\n",
        "        model_output = self.last_dense(concatenated)\n",
        "        \n",
        "        return model_output"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdMFBpdSI1cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_LENGTH = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "CNN_FILTERS = 100\n",
        "DNN_UNITS = 256\n",
        "OUTPUT_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ihUswWhI1aG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
        "                        embedding_dimensions=EMB_DIM,\n",
        "                        cnn_filters=CNN_FILTERS,\n",
        "                        dnn_units=DNN_UNITS,\n",
        "                        model_output_classes=OUTPUT_CLASSES,\n",
        "                        dropout_rate=DROPOUT_RATE)\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUDrC-KgI1Xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "if OUTPUT_CLASSES == 2:\n",
        "    text_model.compile(loss=\"binary_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"accuracy\"])\n",
        "else:\n",
        "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"sparse_categorical_accuracy\"])\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SdtR-ZpI1VR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "47e841e6-84bf-4049-fc91-f9fa11d449c2"
      },
      "source": [
        "text_model.fit(train_data, epochs=NB_EPOCHS,validation_data=test_data)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "704/704 [==============================] - 83s 118ms/step - loss: 0.3534 - accuracy: 0.8354 - val_loss: 0.2596 - val_accuracy: 0.8934\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 64s 90ms/step - loss: 0.1248 - accuracy: 0.9542 - val_loss: 0.3261 - val_accuracy: 0.8846\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 64s 90ms/step - loss: 0.0540 - accuracy: 0.9807 - val_loss: 0.4151 - val_accuracy: 0.8834\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.0472 - accuracy: 0.9821 - val_loss: 0.3733 - val_accuracy: 0.9054\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.4748 - val_accuracy: 0.8906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f51d345d9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT4GBG9sJaQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a83b91dd-723d-49c3-8d5a-86ffbb60358d"
      },
      "source": [
        "loss, accuracy = text_model.evaluate(test_data)\n",
        "print('Test Loss: {}'.format(loss))\n",
        "print('Test Accuracy: {}'.format(accuracy))\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4748 - accuracy: 0.8906\n",
            "Test Loss: 0.4747582972049713\n",
            "Test Accuracy: 0.890625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF1RymJgJak0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Hghkn8-Jan_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}