{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RMDL_BERT.ipynb",
      "provenance": [],
      "mount_file_id": "1dYYIIFUFDy2rXSX8rzLvmAu6JAgPV967",
      "authorship_tag": "ABX9TyPzB8lCWl9Lx066BXuOZUe4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/remanx2558/MIDBReviews/blob/master/RMDL_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMub81zqkQxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "4fdda280-d573-45e7-84b4-ab9cd0bef0d8"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.6/dist-packages (0.14.5)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.9.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDpWHI1xkRT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Htj47jHkRXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import itertools\n",
        "import gensim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import zeros\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clm_nvCJkRav",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "cda0823b-df20-40f2-8a51-d2b34d7f57c4"
      },
      "source": [
        "# Importing dataset\n",
        "reviews_df = pd.read_csv(r\"/content/drive/My Drive/malia/train.csv\")\n",
        "reviews_df.isnull().values.any()\n",
        "reviews_df.sentiment= reviews_df.sentiment.fillna(0.0).astype(int)#this will conver float into int and also manage missing values\n",
        "print(reviews_df.dtypes)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text         object\n",
            "sentiment     int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-YKGOnnkRdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(text):\n",
        "    '''\n",
        "    '''\n",
        "    text = text.lower()\n",
        "    text = text.replace(\"ain't\", \"am not\")\n",
        "    text = text.replace(\"aren't\", \"are not\")\n",
        "    text = text.replace(\"can't\", \"cannot\")\n",
        "    text = text.replace(\"can't've\", \"cannot have\")\n",
        "    text = text.replace(\"'cause\", \"because\")\n",
        "    text = text.replace(\"could've\", \"could have\")\n",
        "    text = text.replace(\"couldn't\", \"could not\")\n",
        "    text = text.replace(\"couldn't've\", \"could not have\")\n",
        "    text = text.replace(\"should've\", \"should have\")\n",
        "    text = text.replace(\"should't\", \"should not\")\n",
        "    text = text.replace(\"should't've\", \"should not have\")\n",
        "    text = text.replace(\"would've\", \"would have\")\n",
        "    text = text.replace(\"would't\", \"would not\")\n",
        "    text = text.replace(\"would't've\", \"would not have\")\n",
        "    text = text.replace(\"didn't\", \"did not\")\n",
        "    text = text.replace(\"doesn't\", \"does not\")\n",
        "    text = text.replace(\"don't\", \"do not\")\n",
        "    text = text.replace(\"hadn't\", \"had not\")\n",
        "    text = text.replace(\"hadn't've\", \"had not have\")\n",
        "    text = text.replace(\"hasn't\", \"has not\")\n",
        "    text = text.replace(\"haven't\", \"have not\")\n",
        "    text = text.replace(\"haven't\", \"have not\")\n",
        "    text = text.replace(\"haven't\", \"have not\")\n",
        "    text = text.replace(\"haven't\", \"have not\")\n",
        "    text = text.replace(\"he'd\", \"he would\")\n",
        "    text = text.replace(\"haven't\", \"have not\")\n",
        "    text = text.replace(\"he'd've\", \"he would have\")\n",
        "    text = text.replace(\"'s\", \"\")\n",
        "    text = text.replace(\"'t\", \"\")\n",
        "    text = text.replace(\"'ve\", \"\")\n",
        "    text = text.replace(\".\", \" . \")\n",
        "    text = text.replace(\"!\", \" ! \")\n",
        "    text = text.replace(\"?\", \" ? \")\n",
        "    text = text.replace(\";\", \" ; \")\n",
        "    text = text.replace(\":\", \" : \")\n",
        "    text = text.replace(\",\", \" , \")\n",
        "    text = text.replace(\"´\", \"\")\n",
        "    text = text.replace(\"‘\", \"\")\n",
        "    text = text.replace(\"’\", \"\")\n",
        "    text = text.replace(\"“\", \"\")\n",
        "    text = text.replace(\"”\", \"\")\n",
        "    text = text.replace(\"\\'\", \"\")\n",
        "    text = text.replace(\"\\\"\", \"\")\n",
        "    text = text.replace(\"-\", \"\")\n",
        "    text = text.replace(\"–\", \"\")\n",
        "    text = text.replace(\"—\", \"\")\n",
        "    text = text.replace(\"[\", \"\")\n",
        "    text = text.replace(\"]\",\"\")\n",
        "    text = text.replace(\"{\",\"\")\n",
        "    text = text.replace(\"}\", \"\")\n",
        "    text = text.replace(\"/\", \"\")\n",
        "    text = text.replace(\"|\", \"\")\n",
        "    text = text.replace(\"(\", \"\")\n",
        "    text = text.replace(\")\", \"\")\n",
        "    text = text.replace(\"$\", \"\")\n",
        "    text = text.replace(\"+\", \"\")\n",
        "    text = text.replace(\"*\", \"\")\n",
        "    text = text.replace(\"%\", \"\")\n",
        "    text = text.replace(\"#\", \"\")\n",
        "    text = text.replace(\"\\n\", \" \\n \")\n",
        "    text = text.replace(\"\\n\", \"\")\n",
        "    text = text.replace(\"_\", \" _ \")\n",
        "    text = text.replace(\"_\", \"\")\n",
        "    text = ''.join([i for i in text if not i.isdigit()])\n",
        "\n",
        "    return text\n",
        "\n",
        "texts = reviews_df['text'].values\n",
        "\n",
        "cleaned_texts = [clean(r) for r in texts] \n",
        "\n",
        "reviews_df['text'] = cleaned_texts\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCaca410kRgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffling data\n",
        "reviews_df = reviews_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Extracting all text\n",
        "texts = reviews_df['text'].values\n",
        "reviews_text = []\n",
        "\n",
        "for p in zip(texts) : \n",
        " reviews_text.append(p)\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yukeWDY-kRjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing training data\n",
        "\n",
        "\n",
        "# Creating datasets\n",
        "dict1 ={\n",
        "    'reviews' : reviews_df['text'],\n",
        "    'labels' : reviews_df['sentiment']\n",
        "}\n",
        "sentiment_df = pd.DataFrame.from_dict(dict1)\n",
        "\n",
        "\n",
        "dict2 ={\n",
        "    'reviews_text' : reviews_df['text']\n",
        "}\n",
        "reviews_text_df = pd.DataFrame.from_dict(dict2)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYgedzVwkRm2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "efc2418b-6ad5-44b3-c872-43e61369fa35"
      },
      "source": [
        "\n",
        "print(sentiment_df[:10])\n",
        "print(reviews_text_df[:10])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             reviews  labels\n",
            "0  a bunch of kids set up a theatre to have an al...       1\n",
            "1  reading my review of the house that screamed ,...       1\n",
            "2  the original lensman series of novels is a cla...       1\n",
            "3  this movie is fun to watch .  if you liked dav...       0\n",
            "4   .  .  . but itll make you wonder if we had an...       1\n",
            "5  at least i was able to enjoy mocking the movie...       1\n",
            "6  i love zombiemovies and i love amateurproducti...       1\n",
            "7  please make me forget .  please .  please .  t...       1\n",
            "8  alright this was quite a sensitive little numb...       0\n",
            "9  the gang of roses .  every rose has its thorns...       0\n",
            "                                        reviews_text\n",
            "0  a bunch of kids set up a theatre to have an al...\n",
            "1  reading my review of the house that screamed ,...\n",
            "2  the original lensman series of novels is a cla...\n",
            "3  this movie is fun to watch .  if you liked dav...\n",
            "4   .  .  . but itll make you wonder if we had an...\n",
            "5  at least i was able to enjoy mocking the movie...\n",
            "6  i love zombiemovies and i love amateurproducti...\n",
            "7  please make me forget .  please .  please .  t...\n",
            "8  alright this was quite a sensitive little numb...\n",
            "9  the gang of roses .  every rose has its thorns...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-kaLZ7skRrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    # Removing html tags\n",
        "    sentence = remove_tags(sen)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZlwLUlYkRuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_AIeHO8neUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = []\n",
        "sentences = list(sentiment_df['reviews'])\n",
        "for sen in sentences:\n",
        "    reviews.append(preprocess_text(sen))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RyajSfwneYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "811c0e40-e96f-47ad-8415-2b518a425848"
      },
      "source": [
        "print(sentiment_df.columns.values)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['reviews' 'labels']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-ULIAPHnecN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9b2d1d0-d92d-45d6-a128-3a6a953ce22f"
      },
      "source": [
        "sentiment_df.labels.unique()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szTdJqH9nefm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9f1cb59d-d605-4824-e9f0-b52f6a7d1013"
      },
      "source": [
        "print(reviews[20])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this piece of filth is virtually impossible to follow the sound is crap the picture quality goes from bad to worse to good to bad again things happen for no apparent reason characters appear and disappear was the director suffering from massive brain injury during its production poor film making aside the story is vile just sick evil sht if you like rape murder and self harm this is right up your alley and if simulated scenes of murder are not enough you can enjoy clips of actual people being executed watched almost all of it but had to turn off after seen someones brains blown out never before have seen film that left me feeling so ashamed and dirty \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUrfQPOLneit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = sentiment_df['labels']\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg-wK_lnnell",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRl34exyneod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(reviews[10]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_THK7w-neut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_reviews(reviews):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(reviews))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbKCD7w7neyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_reviews = [tokenize_reviews(review) for review in reviews]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acse-Q3Nne09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0c90f159-df21-41c5-cc00-2b65f98b167f"
      },
      "source": [
        "print(tokenized_reviews[10])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2096, 2087, 1997, 1996, 3185, 2003, 2200, 5515, 4509, 1996, 12849, 19603, 14574, 3496, 2003, 2209, 2039, 2021, 2025, 4895, 16344, 5657, 12849, 19603, 2375, 2758, 2008, 2019, 4111, 2442, 2022, 9715, 2043, 1996, 6085, 12817, 2009, 3096, 1996, 12849, 19603, 14574, 3496, 2003, 8321, 2004, 3087, 4282, 2040, 2038, 2464, 2028, 2030, 2038, 2464, 1996, 9004, 2050, 2143, 4760, 12849, 19603, 14574, 1999, 2029, 1996, 4176, 3759, 2003, 3013, 1998, 1996, 9686, 7361, 3270, 12349, 3013, 2041, 2096, 2009, 2003, 2145, 4142, 9715, 1998, 5525, 6114, 2057, 2442, 3342, 2008, 2381, 2003, 2517, 2011, 1996, 5125, 2015, 2003, 2028, 2130, 3039, 2000, 2130, 2228, 2008, 2672, 1996, 13157, 2020, 2157, 2515, 2025, 2009, 2360, 2505, 2008, 1996, 13157, 2018, 29131, 2023, 13925, 3412, 14574, 1998, 1996, 5181, 2024, 2145, 12560, 2009, 2130, 2651]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQG0EEDIne4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_with_len = [[review, y[i]]\n",
        "                 for i, review in enumerate(tokenized_reviews)]"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krHK_vi9ne7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.shuffle(reviews_with_len)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nYK5R0pkRxd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "37164963-2429-4e3c-b47d-76d2f1bd3e33"
      },
      "source": [
        "print(reviews_with_len[:2])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[3731, 3423, 2038, 2357, 2049, 5725, 1998, 2003, 3753, 2005, 1996, 8659, 2341, 1998, 16215, 10369, 22889, 7361, 2009, 2038, 2580, 2043, 2023, 2265, 2034, 4836, 2471, 2176, 2161, 2067, 2009, 2001, 14742, 14308, 2012, 1996, 3423, 2291, 2029, 2035, 5889, 4025, 2000, 2202, 6620, 1999, 17274, 2009, 2001, 6057, 24908, 1998, 2000, 2070, 6698, 25854, 1996, 3494, 6791, 2020, 11701, 1998, 2000, 2019, 6698, 2613, 1999, 2037, 13954, 2015, 1996, 4424, 7615, 1998, 4023, 2020, 3132, 1998, 14742, 7628, 16208, 2003, 1998, 2001, 3376, 2004, 1999, 2060, 2186, 2016, 4194, 2021, 2003, 2085, 7944, 2000, 1996, 2896, 11143, 1997, 2865, 4730, 1997, 3348, 1998, 4808, 7628, 2003, 2019, 6581, 3883, 1998, 3791, 2062, 6540, 4132, 2084, 2023, 2537, 10731, 4748, 9103, 4103, 12083, 10054, 2003, 2019, 6581, 3364, 2040, 2038, 2013, 1996, 2420, 1997, 11999, 2000, 2023, 2537, 2218, 2010, 2219, 1999, 1996, 2492, 1997, 4024, 2467, 4760, 1996, 8562, 1998, 26438, 3772, 1997, 1996, 2537, 2952, 11332, 2003, 6057, 1998, 14742, 2003, 22905, 15214, 2319, 1998, 2003, 2000, 2022, 12749, 2005, 2014, 5719, 1999, 2023, 2537, 1998, 2003, 2204, 3883, 2508, 23288, 2099, 2045, 2003, 2053, 4797, 1999, 2010, 3772, 3754, 2174, 2002, 2323, 2175, 2067, 2000, 2010, 22038, 2595, 7321, 2107, 2004, 5823, 2004, 2009, 3544, 2002, 2038, 2172, 5848, 1998, 21970, 1999, 2008, 3257, 2057, 3198, 2008, 2023, 2186, 2022, 11669, 2098, 2004, 2009, 2525, 2003, 1998, 2049, 2428, 3225, 2000, 5437], 1], [[3100, 2023, 2038, 2042, 8837, 2144, 2001, 4379, 2079, 2025, 3422, 2009, 3674, 2335, 2095, 4902, 2021, 2023, 2003, 2025, 3185, 2005, 2019, 3080, 4245, 2040, 2215, 6748, 3574, 2030, 2070, 8235, 4471, 2023, 3185, 2003, 4569, 2009, 3492, 6052, 2471, 3413, 2063, 2021, 6262, 13382, 2100, 2003, 2061, 8235, 2008, 2009, 23653, 2065, 2017, 2215, 2000, 2022, 11084, 2098, 2011, 6350, 2012, 14381, 3230, 23289, 2015, 2030, 2293, 6262, 2023, 3185, 2003, 2005, 2017, 4728, 2079, 2025, 8572], 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-MkrIgmoTKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "a09a4773-eb05-47a4-baa8-d8f078d36fe4"
      },
      "source": [
        "reviews_with_len.sort(key=lambda x: x[2])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-3be825373ff8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreviews_with_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-79-3be825373ff8>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreviews_with_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkc98bOKrUtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_reviews_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJsfQeC3rVGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_reviews_labels, output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "briMUdX5rVPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VdIJkBorVaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "c5c3e2fd-db6f-4541-925b-e36b33a89913"
      },
      "source": [
        "next(iter(batched_dataset))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 1614), dtype=int32, numpy=\n",
              " array([[ 3731,  3423,  2038, ...,     0,     0,     0],\n",
              "        [ 3100,  2023,  2038, ...,     0,     0,     0],\n",
              "        [ 1045,  2034,  2387, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [ 3958, 12385,  3240, ...,     0,     0,     0],\n",
              "        [10047,  2183,  2000, ...,     0,     0,     0],\n",
              "        [10882,  3527,  2003, ...,     0,     0,     0]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 1, 1, 0, 1, 0], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJulhY0TrVee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "TOTAL_BATCHES = math.ceil(len(sorted_reviews_labels) / BATCH_SIZE)\n",
        "TEST_BATCHES = TOTAL_BATCHES // 10\n",
        "batched_dataset.shuffle(TOTAL_BATCHES)\n",
        "test_data = batched_dataset.take(TEST_BATCHES)\n",
        "train_data = batched_dataset.skip(TEST_BATCHES)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scPAGMO1rwXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDTCQZsFrwvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class TEXT_MODEL(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 embedding_dimensions=128,\n",
        "                 cnn_filters=50,\n",
        "                 dnn_units=512,\n",
        "                 model_output_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"text_model\"):\n",
        "        super(TEXT_MODEL, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocabulary_size,\n",
        "                                          embedding_dimensions)\n",
        "        #self.rnn_layer = layers.Bidirectional(self.rnn_layer.layers.LSTM(32)),\n",
        "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=2,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=3,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=4,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if model_output_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=model_output_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        l = self.embedding(inputs)\n",
        "        l_1 = self.cnn_layer1(l) \n",
        "        l_1 = self.pool(l_1) \n",
        "        l_2 = self.cnn_layer2(l) \n",
        "        l_2 = self.pool(l_2)\n",
        "        l_3 = self.cnn_layer3(l)\n",
        "        l_3 = self.pool(l_3) \n",
        "        concatenated = tf.concat([l_1, l_2, l_3,], axis=-1) # (batch_size, 4 * rmdl_filters)\n",
        "        concatenated = self.dense_1(concatenated)\n",
        "        concatenated = self.dropout(concatenated, training)\n",
        "        model_output = self.last_dense(concatenated)\n",
        "        \n",
        "        return model_output"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE41UrhQrwzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_LENGTH = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "CNN_FILTERS = 100\n",
        "DNN_UNITS = 256\n",
        "OUTPUT_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgVq4YQmrw3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
        "                        embedding_dimensions=EMB_DIM,\n",
        "                        cnn_filters=CNN_FILTERS,\n",
        "                        dnn_units=DNN_UNITS,\n",
        "                        model_output_classes=OUTPUT_CLASSES,\n",
        "                        dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0N1eX5srw7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if OUTPUT_CLASSES == 2:\n",
        "    text_model.compile(loss=\"binary_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"accuracy\"])\n",
        "else:\n",
        "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBARigltrw_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "dc9e32af-652c-4fed-cd4f-a97bab79f105"
      },
      "source": [
        "text_model.fit(train_data, epochs=NB_EPOCHS)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "704/704 [==============================] - 140s 199ms/step - loss: 0.3605 - accuracy: 0.8303\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 90s 128ms/step - loss: 0.1321 - accuracy: 0.9529\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 91s 129ms/step - loss: 0.0463 - accuracy: 0.9829\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 88s 126ms/step - loss: 0.0292 - accuracy: 0.9894\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 89s 126ms/step - loss: 0.0204 - accuracy: 0.9925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fec35bfb0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lt99pAorxCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "954aa13f-2dad-4636-d23f-ad69654fa08e"
      },
      "source": [
        "loss, accuracy = text_model.evaluate(test_data)\n",
        "print('Test Loss: {}'.format(loss))\n",
        "print('Test Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78/78 [==============================] - 4s 46ms/step - loss: 1.0204 - accuracy: 0.8241\n",
            "Test Loss: 1.0204379558563232\n",
            "Test Accuracy: 0.8241186141967773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYHPvjtDsKjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M1F3wiCsKnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK_eZeFmsKrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}